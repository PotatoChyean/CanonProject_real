"""
ëª¨ë¸ ì¶”ë¡  í†µí•© ë¡œì§ (ìˆ˜ì • ë° í†µí•© ë²„ì „)
YOLO, ConditionalViT (CNN) ëª¨ë¸ì„ ì—°ê²°í•˜ì—¬ 7ë‹¨ê³„ ê·œì¹™ ê¸°ë°˜ Pass/Fail ë° ì œí’ˆ ëª¨ë¸ ë¶„ë¥˜
"""

import numpy as np
import torch
from typing import Dict, List, Optional
from PIL import Image
from collections import Counter #! ===== ìˆ˜ì •/ì¶”ê°€ =====
from ultralytics import YOLO
from torchvision import transforms
from transformers import ViTModel
import io
import os
import traceback

# ì™¸ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸ 
from models.yolo_model import YOLOModel
from models.cnn_model import CNNModel

from .cnn_model import ConditionalViT


# ============================================================
# ì œí’ˆ ìŠ¤í™í…Œì´ë¸” ë° ë ˆì´ë¸” #! ===== ìˆ˜ì •/ì¶”ê°€ =====
# ============================================================
PRODUCT_SPEC = {
    "FM2-V160-000": {"button": "ID",   "lang": "CN"},
    "FM2-V161-000": {"button": "STAT", "lang": None},
    "FM2-V162-000": {"button": "STAT", "lang": "EN"},
    "FM2-V163-000": {"button": "STAT", "lang": "CN"},
    "FM2-V164-000": {"button": "STAT", "lang": "KR"},
    "FM2-V165-000": {"button": "STAT", "lang": "TW"},
    "FM2-V166-000": {"button": "ID",   "lang": "EN"},
    "FM2-V167-000": {"button": "STAT", "lang": "JP"},
}

LANG_LABEL = ["CN", "EN", "JP", "KR", "TW"]

# YOLO í´ë˜ìŠ¤ ì´ë¦„ (ì´ì „ ê·œì¹™ì— ë§ê²Œ ì¬ì •ì˜)
# 0: Home, 1: Back, 2: ID, 3: Stat, 4: Monitor, 5: Text
CLASS_NAMES = ['Home', 'Back', 'ID', 'Stat', 'Monitor', 'Text', 'Monitor_Small', 'Monitor_Big', 'sticker']
CLASS_MAP = { 
    0: 'Home', 1: 'Back', 2: 'ID', 3: 'Stat', 4: 'Monitor', 5: 'Text', 
    6: 'Monitor_Small', 7: 'Monitor_Big', 8: 'sticker'
}

# ì „ì—­ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
yolo_model = None
cnn_model = None
transform = None
DEVICE = "cpu"

# ============================================================
# ì œí’ˆ ëª¨ë¸ ìë™ ë¶„ë¥˜ í•¨ìˆ˜ #! ===== ìˆ˜ì •/ì¶”ê°€ =====
# ============================================================
def classify_model(found_back, found_id, text_langs):

    # (1) í…ìŠ¤íŠ¸ ì–¸ì–´ ê²°ì • (N=0 ë˜ëŠ” N>=3ì¼ ë•Œë§Œ í˜¸ì¶œëœë‹¤ê³  ê°€ì •)
    if len(text_langs) == 0:
        lang = None
    else:
        # N >= 3ì¸ ê²½ìš° ë‹¤ìˆ˜ê²° (majority)
        lang = Counter(text_langs).most_common(1)[0][0] 

    # (2) Back/ID ê²°ì •
    if found_back and (not found_id):
        btn_type = "STAT"  # Back â†’ STAT ëª¨ë¸êµ°
    elif found_id and (not found_back):
        btn_type = "ID"
    else:
        # ì´ ì—ëŸ¬ëŠ” analyze_imageì˜ yolo_xor_okì—ì„œ ì´ë¯¸ ê±¸ëŸ¬ì§€ì§€ë§Œ, ëª…ì‹œì ìœ¼ë¡œ ë°˜í™˜
        return None, "Back/ID Mismatch (XOR Fail)" 

    # (3) í›„ë³´ ì œí’ˆ ì°¾ê¸°
    candidates = []
    for name, spec in PRODUCT_SPEC.items():
        if spec["lang"] == lang and spec["button"] == btn_type:
            candidates.append(name)

    if len(candidates) == 1:
        return candidates[0], None # ì„±ê³µ
    elif len(candidates) > 1:
        return None, "AmbiguousModel" # ì‹¤íŒ¨
    else:
        return None, "UnknownModel" # ì‹¤íŒ¨

# ============================================================
# NumPy íƒ€ì… ë³€í™˜ í•¨ìˆ˜ (ê¸°ì¡´ ìœ ì§€)
# ============================================================
def convert_numpy_types(data):
    """
    ë¶„ì„ ê²°ê³¼ì— í¬í•¨ëœ NumPy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ì¬ê·€ì ìœ¼ë¡œ ë³€í™˜
    """
    if isinstance(data, dict):
        return {k: convert_numpy_types(v) for k, v in data.items()}
    if isinstance(data, (list, tuple)):
        return [convert_numpy_types(i) for i in data]
    if isinstance(data, np.integer):
        return int(data)
    if isinstance(data, np.floating):
        return float(data)
    if isinstance(data, np.ndarray):
        return data.tolist()
    return data

# ============================================================
# ëª¨ë¸ ì´ˆê¸°í™” í•¨ìˆ˜ (ìˆ˜ì •) #! ===== ìˆ˜ì • =====
# ============================================================
def initialize_models(
    yolo_path: str = "models/YOLO.pt",
    cnn_path: str = "models/CNN_classifier.pt",
):
    """ëª¨ë¸ ì´ˆê¸°í™” (ì„œë²„ ì‹œì‘ ì‹œ í˜¸ì¶œ)"""
    global yolo_model, cnn_model, transform, DEVICE
    
    # YOLO ëª¨ë¸ ì´ˆê¸°í™” (YOLOModelì€ ì™¸ë¶€ ëª¨ë“ˆ ê°€ì •)
    if yolo_model is None:
        yolo_model = YOLOModel(model_path=yolo_path)

    # CNN/Text ëª¨ë¸ ì´ˆê¸°í™” (ì¶”ê°€)
    if cnn_model is None:
        try:
            DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
            print(f"Using device: {DEVICE}")
            
            cnn_model = ConditionalViT() 
            cnn_model.load_state_dict(torch.load(cnn_path, map_location=DEVICE))
            cnn_model.eval()
            cnn_model = cnn_model.to(DEVICE)

            # ì´ë¯¸ì§€ ë³€í™˜ ì •ì˜
            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
            ])
            print("CNN/Text ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
        except Exception as e:
            print(f"CNN/Text ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            cnn_model = None
            
    return yolo_model, cnn_model

# ============================================================
# ì´ë¯¸ì§€ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜ (ì „ë©´ ìˆ˜ì •) #! ===== ì „ë©´ ìˆ˜ì • =====
# ============================================================
def analyze_image(image: np.ndarray) -> Dict:
    """
    ì´ë¯¸ì§€ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜: 7ë‹¨ê³„ ë³µí•© ê²€ì‚¬ íŒŒì´í”„ë¼ì¸ ìˆ˜í–‰
    """
    # ëª¨ë¸ ì´ˆê¸°í™” í™•ì¸
    if yolo_model is None or cnn_model is None or transform is None:
        initialize_models()
        if cnn_model is None:
             raise RuntimeError("CNN/Text ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ˆê¸°í™” ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    try:
        # ì´ë¯¸ì§€ë¥¼ PIL Imageë¡œ ë³€í™˜ (RGBë¡œ ë³€í™˜)
        if len(image.shape) == 3 and image.shape[2] == 3:
            pil_img = Image.fromarray(image).convert("RGB")
        else:
            pil_img = Image.fromarray(image).convert("RGB") 

        # 1. YOLO ê°ì²´ ê²€ì¶œ
        yolo_results = yolo_model.detect(image) 
        detected_classes_raw = [d["class"] for d in yolo_results.get("detections", [])]
        
        # --- 2. YOLO ê²°ê³¼ í”Œë˜ê·¸ ì´ˆê¸°í™” ë° CNN ë°ì´í„° ìˆ˜ì§‘ ---
        found_home = False
        found_stat = False
        found_monitor = False
        found_back = False
        found_id = False

        cnn_results = []
        roi_pass_list = [] # ë²„íŠ¼ CNN PASS/FAIL ê²°ê³¼ë§Œ ì €ì¥
        text_langs = []
        
        button_classes = ['Home', 'Back', 'ID', 'Stat', 'Btn_Home', 'Btn_Back', 'Btn_ID', 'Btn_Stat']
        
        for detection in yolo_results.get("detections", []):
            cls_name = detection["class"]
            bbox = detection["bbox"]
            crop_pil = pil_img.crop((bbox[0], bbox[1], bbox[2], bbox[3])) 
            
            # í”Œë˜ê·¸ ì„¤ì •
            if cls_name in ['Home', 'Btn_Home']: found_home = True    # ğŸš¨ ìˆ˜ì •ë¨
            elif cls_name in ['Back', 'Btn_Back']: found_back = True  # ğŸš¨ ìˆ˜ì •ë¨
            elif cls_name in ['ID', 'Btn_ID']: found_id = True        # ğŸš¨ ìˆ˜ì •ë¨ (IDë„ Btn_IDë¡œ íƒì§€ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ í¬í•¨)
            elif cls_name in ['Stat', 'Btn_Stat']: found_stat = True  # ğŸš¨ ìˆ˜ì •ë¨
            elif cls_name == 'Monitor': found_monitor = True # Monitor í´ë˜ìŠ¤ ê°€ì •
            elif cls_name in ['Monitor_Small', 'Monitor_Big']: found_monitor = True # í™•ì¥ Monitor í´ë˜ìŠ¤ ëŒ€ì‘
            
            # --- 3. CNN ìˆ˜í–‰ (ë²„íŠ¼ & í…ìŠ¤íŠ¸) ---
            
            if cls_name in button_classes:
                # CNN head_btn (cond = 0): Pass/Fail ë¶„ë¥˜
                cond = torch.tensor([0]).to(DEVICE)
                with torch.no_grad():
                    t = transform(crop_pil).unsqueeze(0).to(DEVICE)
                    out = cnn_model(t, cond)[0]
                
                prob_pass = torch.softmax(out[:2], dim=0)[0].item() # Pass í™•ë¥ 
                is_pass = (torch.argmax(out[:2]).item() == 0) # 0ì´ Pass
                
                roi_pass_list.append(is_pass) # ëª¨ë“  íƒì§€ëœ ë²„íŠ¼ì— ëŒ€í•´ í’ˆì§ˆ ì²´í¬
                
                cnn_results.append({
                    "class": cls_name,
                    "bbox": bbox,
                    "probability": round(prob_pass, 4), 
                    "status": "Pass" if is_pass else "Fail"
                })

            elif cls_name == 'Text':
                # CNN head_txt (cond = 1): ì–¸ì–´ ë¶„ë¥˜
                cond = torch.tensor([1]).to(DEVICE)
                with torch.no_grad():
                    t = transform(crop_pil).unsqueeze(0).to(DEVICE)
                    out = cnn_model(t, cond)[0]
                
                lang_idx = torch.argmax(out).item()
                lang = LANG_LABEL[lang_idx]
                prob_lang = torch.softmax(out, dim=0)[lang_idx].item()
                
                text_langs.append(lang)
                
                cnn_results.append({
                    "class": cls_name,
                    "bbox": bbox,
                    "probability": round(prob_lang, 4), 
                    "status": "OK", 
                    "lang": lang
                })

        # --- 4. 7ê°€ì§€ ê·œì¹™ ê¸°ë°˜ íŒì • ì‹œì‘ ---
        
        # Rule A: YOLO ì¡´ì¬ ì¡°ê±´ (Home, Stat, Monitor)
        yolo_presence_ok = found_home and found_stat and found_monitor
        
        # Rule B: Back XOR ID ì¡°ê±´
        yolo_xor_ok = found_back ^ found_id
        
        # Rule C: ë²„íŠ¼ CNN PASS ì¡°ê±´ (ëª¨ë“  íƒì§€ëœ ë²„íŠ¼)
        cnn_ok = all(roi_pass_list) if roi_pass_list else False

        # Rule D: í…ìŠ¤íŠ¸ ê°œìˆ˜ ì¡°ê±´ (N=0 ë˜ëŠ” N>=3)
        text_count = len(text_langs)
        text_ok = (text_count == 0) or (text_count >= 3)

        # Rule E: ì œí’ˆ ëª¨ë¸ ë¶„ë¥˜ ì„±ê³µ
        detected_prod, model_err = classify_model(found_back, found_id, text_langs)
        model_ok = (detected_prod is not None)
        
        # --- 5. ìµœì¢… íŒì • ---
        final_pass = yolo_presence_ok and yolo_xor_ok and cnn_ok and text_ok and model_ok
        final_status = "PASS" if final_pass else "FAIL" 
        
        # --- 6. Fail ì‚¬ìœ  ìˆ˜ì§‘ ---
        reasons = []
        if not yolo_presence_ok: reasons.append("í•„ìˆ˜ ê°ì²´ ë¯¸ê²€ì¶œ (Home/Stat/Monitor)")
        if not yolo_xor_ok: reasons.append("Back/ID ì¡°ê±´ ë¶ˆë§Œì¡± (XOR ì‹¤íŒ¨)")
        if not cnn_ok: reasons.append("ë²„íŠ¼ CNN ê²€ì¦ ì‹¤íŒ¨")
        if not text_ok: reasons.append(f"í…ìŠ¤íŠ¸ ê°œìˆ˜ ë¶ˆë§Œì¡± (N={text_count})")
        
        if not model_ok: reasons.append(model_err) 

        reason = "; ".join(reasons) if reasons else None
        
        # --- 7. ì‹ ë¢°ë„ ê³„ì‚° ë° ê²°ê³¼ êµ¬ì„± (ê¸°ì¡´ ë¡œì§ í™œìš©) ---
        confidence_scores = []
        for detection in yolo_results.get("detections", []):
            confidence_scores.append(detection.get("confidence", 0) * 100)
        for cnn_result in cnn_results:
            confidence_scores.append(cnn_result.get("probability", 0) * 100)
        
        avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0
        
        final_result = {
            "status": final_status,
            "reason": reason,
            "confidence": round(avg_confidence, 2),
            "details": {
                "product_model": detected_prod,
                "language": Counter(text_langs).most_common(1)[0][0] if text_langs else None,
                "yolo_status": "Pass" if (yolo_presence_ok and yolo_xor_ok) else "Fail",
                "cnn_status": "Pass" if cnn_ok else "Fail",
                "model_status": "Pass" if model_ok else "Fail",
                "text_count": text_count,
                "yolo_detections": yolo_results.get("detections", []),
                "cnn_results": cnn_results, 
                "detected_classes": detected_classes_raw
            }
        }
        return convert_numpy_types(final_result)
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        error_result = {
            "status": "FAIL",
            "reason": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__} - {str(e)}",
            "confidence": 0,
            "details": {}
        }
        return convert_numpy_types(error_result)


def analyze_frame(image: np.ndarray) -> Dict:
    """
    ì‹¤ì‹œê°„ í”„ë ˆì„ ë¶„ì„ (analyze_imageì™€ ë™ì¼)
    """
    # analyze_imageì™€ ë™ì¼ ë¡œì§ì„ ì‚¬ìš©í•˜ë˜, ì¶”í›„ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ ë¶„ë¦¬ë¨
    return analyze_image(image)